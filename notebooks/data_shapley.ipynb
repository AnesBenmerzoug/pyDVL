{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\phi_i = C \\sum_{S \\subset D \\backslash \\{i\\}} \\frac{1}{{n-1} \\choose {|S|}} [V(S \\cup \\{i\\})-V(S)]$$\n",
    "\n",
    "$$ \\phi_i = \\mathbb{E}_{\\pi \\sim \\Pi} [V(S^i_{\\pi} \\cup {\\{i\\}})-V(S^i_{\\pi})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. n = number of training samples\n",
    "1. values = -np.inf * np.ones(n)\n",
    "1. scores = [[] for _ in range(n)]\n",
    "1. For i in (1,n):\n",
    "    1. iteration = 0\n",
    "    1. while iteration < max_iterations:\n",
    "        1. Draw an n-permutation\n",
    "        1. model.fit(samples(permutation(:index(i))))\n",
    "        1. score_without = model.predict(test set)\n",
    "        1. model.fit(samples(permutation(:index(i)+1)))\n",
    "        1. score_with = model.predict(test set)\n",
    "        1. old_moving_average = mean(scores(i))\n",
    "        1. scores(i).push(score_with - score_without)\n",
    "        1. new_moving_average = mean(scores(i))\n",
    "        1. if abs(new_moving_average - old_moving_average) < eps then break\n",
    "        1. old_moving_average = new_moving_average \n",
    "        1. iteration += 1\n",
    "    1. values(i) = mean(scores(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from valuation.utils import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_sklearn(datasets.load_boston())\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(data.x_train, data.y_train)\n",
    "predictions = model.predict(data.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(data.y_test, predictions)\n",
    "plt.plot([0, 50], [0, 50], '--k')\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.shapley import naive_montecarlo_shapley, truncated_montecarlo_shapley\n",
    "from valuation.utils import run_and_gather, parallel_wrap\n",
    "from valuation.reporting.scores import compute_fb_scores\n",
    "from valuation.reporting.plots import shapley_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive MCShapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iterations = 200\n",
    "fun = partial(naive_montecarlo_shapley, model, data,\n",
    "              max_iterations=max_iterations, tolerance=None)\n",
    "wrapped = parallel_wrap(fun, (\"indices\", data.indices), num_jobs=160)\n",
    "values_nmcs, hist_nmcs = run_and_gather(wrapped, num_runs=10, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nmcs = compute_fb_scores(values_nmcs, model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nmcs.update({'max_iterations': max_iterations, 'score_name': \"$R^2$\"})\n",
    "shapley_results(scores_nmcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated MC Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bootstrap_iterations': 200,\n",
    "          'min_scores': 10,\n",
    "          'score_tolerance': 0.1,\n",
    "          'min_values': 10,\n",
    "          'value_tolerance': 1e-2,\n",
    "          'max_iterations': 0.5*len(data)}\n",
    "fun = partial(truncated_montecarlo_shapley, \n",
    "              model, data, num_workers=160, worker_progress=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_mcs, hist_mcs = run_and_gather(fun, num_runs=10, progress_bar=False)  # montecarlo_shapley already provides a bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nmcs = compute_fb_scores(values_nmcs, model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mcs.update({'max_iterations': params['max_iterations'], 'score_name': \"$R^2$\"})\n",
    "shapley_results(scores_mcs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
