{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dval - Shapley for data valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces Dval, a library to evaluate the importance of single datapoints in the performance of machine learning models.\n",
    "We will go through the foundations of the library, its main entry-points and capabilities working with a real dataset of music tracks.\n",
    "We will also highlight the advantages of using our library over vanilla data-shapley calculations, showing explicitly the advantages in runtime and efficiency for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/top_hits_spotify_dataset.csv')\n",
    "data = data[data['year']> 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'popularity'\n",
    "y = data[target_column]\n",
    "X = data.drop(target_column, axis=1)\n",
    "X['genre'] = data['genre'].astype('category').cat.codes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name = X_train['song']\n",
    "artist = X_train['artist']\n",
    "X_train = X_train.drop(['song', 'artist'], axis=1)\n",
    "X_test = X_test.drop(['song', 'artist'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Make sure to restart (or simply start if it is not already running) your memcache. In the terminal, type\n",
    "\n",
    "`sudo service memcached restart`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.shapley import create_utility, shapley_dval\n",
    "utility = create_utility(model=RandomForestRegressor(n_estimators=10), x_train=X_train, y_train=y_train, x_test=X_test, y_test=y_test, scoring='r2', data_groups=artist,)\n",
    "values, val_std = shapley_dval(utility, max_iterations=100, num_jobs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval_df = pd.DataFrame(list(zip(values.keys(), values.values(), val_std.values())), columns=['song', 'shapley_dval', 'dval_std'])\n",
    "low_dval = dval_df.iloc[:30]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.errorbar(x=low_dval['song'], y=low_dval['shapley_dval'], yerr=low_dval['dval_std'], fmt='o')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, val_std = shapley_dval(utility, max_iterations=100, num_jobs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval_df = pd.DataFrame(list(zip(values.keys(), values.values(), val_std.values())), columns=['song', 'shapley_dval', 'dval_std'])\n",
    "low_dval = dval_df.iloc[:30]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.errorbar(x=low_dval['song'], y=low_dval['shapley_dval'], yerr=low_dval['dval_std'], fmt='o')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_dval = dval_df.iloc[-30:]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.errorbar(x=high_dval['song'], y=high_dval['shapley_dval'], yerr=high_dval['dval_std'], fmt='o')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of anomalous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_drake_popularity = data[data['artist'] == 'Drake']['popularity'] - data[data['artist'] == 'Drake']['popularity']\n",
    "data.loc[data['artist'] == 'Drake', 'popularity'] = new_drake_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(data.y_test, predictions)\n",
    "plt.plot([0, 50], [0, 50], '--k')\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.shapley import permutation_exact_shapley, truncated_montecarlo_shapley\n",
    "from valuation.utils import map_reduce, Utility\n",
    "from valuation.reporting.scores import compute_fb_scores\n",
    "from valuation.reporting.plots import shapley_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Shapley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to examine how the shapley values change with train and test data. In particular, we want to examine how robust data shapley values are to out of distribution input data. To do so, we will progressively add more and more outliers to our train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from valuation.utils.dataset import polynomial_dataset, polynomial\n",
    "\n",
    "d, coeffs = polynomial_dataset(np.random.randint(-3, 3, size=3))  \n",
    "model = make_pipeline(PolynomialFeatures(len(coeffs)-1), LinearRegression())\n",
    "\n",
    "n = len(d)\n",
    "model.fit(d.x_train, d.y_train)\n",
    "predicted = [model.predict(d.x_test)]\n",
    "\n",
    "x_cont = d.x_train.reshape(-1,) + np.random.uniform(-0.05, 0.05, size=len(d))\n",
    "x_cont = x_cont[::2]\n",
    "y_cont = polynomial(np.random.normal(loc=coeffs, scale=0.3), x_cont)\n",
    "xtrain = np.concatenate([d.x_train, x_cont.reshape(-1, 1)], axis=0)\n",
    "ytrain = np.concatenate([d.y_train, y_cont.reshape(-1,)], axis=0)\n",
    "for i in range(len(d), len(xtrain)):\n",
    "    model.fit(xtrain[:i+1], ytrain[:i+1])\n",
    "    ypred = model.predict(d.x_test)\n",
    "    predicted.append(ypred)\n",
    "\n",
    "test_indices = np.argsort(d.x_test, axis=0).reshape(-1, )\n",
    "xx = np.arange(-1, 1, 0.1)\n",
    "yy = polynomial(coeffs, xx)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "for i, ypred in enumerate(predicted):\n",
    "    plt.figure(dpi=300)\n",
    "    plt.scatter(d.x_train[:n], d.y_train[:n], label=\"Training (in-dist)\")\n",
    "    plt.scatter(d.x_test, d.y_test, label=\"Test\")\n",
    "\n",
    "    if i > 0:\n",
    "        plt.scatter(x_cont[:i], y_cont[:i], label=\"Training (out of dist)\")\n",
    "    plt.plot(xx, yy, label=\"True\")\n",
    "    plt.plot(d.x_test[test_indices], ypred[test_indices], label=\"Predicted\")\n",
    "    plt.ylim(min(d.y_train[:n].min(), y_cont.min()) - 1,\n",
    "                max(d.y_train[:n].max(), y_cont.max()) + 1)\n",
    "    plt.legend()\n",
    "    plt.title(d.description)\n",
    "    plt.show()\n",
    "\n",
    "d.x_train = xtrain\n",
    "d.y_train = ytrain\n",
    "\n",
    "from valuation.shapley import combinatorial_exact_shapley\n",
    "from valuation.utils import Utility\n",
    "u = Utility(model, d, \"neg_median_absolute_error\")\n",
    "values = combinatorial_exact_shapley(u, progress=False)\n",
    "high_to_low = list(reversed(values))\n",
    "\n",
    "take = 5\n",
    "plt.figure(dpi=300)\n",
    "plt.scatter(d.x_train[:n], d.y_train[:n], label=\"Training (in-dist)\")\n",
    "plt.scatter(d.x_test, d.y_test, label=\"Test\")\n",
    "plt.scatter(d.x_train[high_to_low][:take], d.y_train[high_to_low][:take],\n",
    "            marker='x', label='High value')\n",
    "plt.scatter(x_cont, y_cont, label=\"Training (out of dist)\")\n",
    "plt.plot(xx, yy, label=\"True\")\n",
    "plt.plot(d.x_test[test_indices], predicted[-1][test_indices], label=\"Predicted\")\n",
    "\n",
    "model.fit(d.x_train[high_to_low][:take], d.y_train[high_to_low][:take])\n",
    "ypred = model.predict(d.x_test)\n",
    "plt.plot(d.x_test, ypred, label='High: prediction')\n",
    "plt.title(d.description)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCShapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 200\n",
    "utility = Utility(\n",
    "    model,\n",
    "    data,\n",
    "    scoring=None,\n",
    "    enable_cache=False,\n",
    ")\n",
    "fun = partial(permutation_exact_shapley, utility=utility, progress=True)\n",
    "values_nmcs, hist_nmcs = map_reduce(fun, num_runs=10, num_jobs=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nmcs = compute_fb_scores(model=model, data=data, values=values_nmcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nmcs.update({'max_iterations': max_iterations, 'score_name': \"$R^2$\"})\n",
    "shapley_results(scores_nmcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated MC Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bootstrap_iterations': 200,\n",
    "          'min_scores': 10,\n",
    "          'score_tolerance': 0.1,\n",
    "          'min_values': 10,\n",
    "          'value_tolerance': 1e-2,\n",
    "          'max_iterations': 0.5*len(data)}\n",
    "fun = partial(truncated_montecarlo_shapley, \n",
    "              model, data, num_workers=160, worker_progress=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_mcs, hist_mcs = map_reduce(fun, data=data, num_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mcs = compute_fb_scores(model=model, data=data, values=values_mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mcs.update({'max_iterations': params['max_iterations'], 'score_name': \"$R^2$\"})\n",
    "shapley_results(scores_mcs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dval_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "eba46eb839f657297a67dfcab4ecbbdeadd901c8566c6569235ade442dd27358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
