{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75acfec",
   "metadata": {},
   "source": [
    "# Clean dataset using influence functions and neural networks\n",
    "\n",
    "A dataset usually consists of a lot of data points, while not all data points are equally important for achieving the desired accuracy. Sometimes it is necessary to speed up the gradient calculations or optimize the required RAM. Example applications are reinforcement learning or continuous optimal control tasks. This notebook\n",
    "\n",
    "- shows how to calculate influences using the pyDVL library of an arbitrary (usually called training) set of data samples $X_\\text{train} \\subseteq \\mathbb{R}^d$ onto a test set $X_\\text{test} \\subseteq \\mathbb{R}^d$.\n",
    "- shows a plot with the weighted F1-score on the y-axis and the number of samples on the x-axis.\n",
    "- selects the optimal number of samples for the dataset as induced by the influence functions.\n",
    "\n",
    "First, an arbitrary random dataset can be loaded or created using the ```utils.dataset.Dataset``` class. For showcase purposes the wine dataset is used. It can be loaded (as any other compatible dataset) directly from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be813151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from valuation.utils.dataset import Dataset\n",
    "\n",
    "wine_bunch = load_wine(as_frame=True)\n",
    "dataset = Dataset.from_sklearn(wine_bunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a018e72c",
   "metadata": {},
   "source": [
    "## Fit a neural network to the data\n",
    "\n",
    "First, a 2-layer neural network is created and fitted with pyDVL. This can be achieved by the following code snippet. It creates a 2-layer neural network with 16 neurons in each hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00dc59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import torch\n",
    "from valuation.influence.model_wrappers import TorchNeuralNetwork, fit_torch_model\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "import numpy as np\n",
    "\n",
    "x_transformer = MinMaxScaler()\n",
    "\n",
    "transformed_dataset = copy(dataset)\n",
    "x_train = x_transformer.fit_transform(transformed_dataset.x_train)\n",
    "transformed_dataset.x_train = torch.tensor(x_train, dtype=torch.float)\n",
    "transformed_dataset.y_train = torch.tensor(transformed_dataset.y_train, dtype=torch.long)\n",
    "x_test = x_transformer.transform(transformed_dataset.x_test)\n",
    "transformed_dataset.y_test = torch.tensor(transformed_dataset.y_test, dtype=torch.long)\n",
    "transformed_dataset.x_test = torch.tensor(x_test, dtype=torch.float)\n",
    "feature_dimension = transformed_dataset.x_train.shape[1]\n",
    "unique_classes = np.unique(np.concatenate((dataset.y_train, dataset.y_test)))\n",
    "num_classes = len(unique_classes)\n",
    "network_size = [16, 16]\n",
    "num_epochs = 300\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nn = TorchNeuralNetwork(feature_dimension, num_classes, network_size)\n",
    "nn.to(device)\n",
    "optimizer = Adam(params=nn.parameters(), lr= 0.001, weight_decay= 0.001)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "fit_torch_model(\n",
    "    model=nn,\n",
    "    x=transformed_dataset.x_train,\n",
    "    y=transformed_dataset.y_train,\n",
    "    loss=F.cross_entropy,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3345522",
   "metadata": {},
   "source": [
    "A short visual inspection yields that all labels of the test set are now classified correctly. This can be verified with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08f1cba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f883d4d9420>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "pred_y_train = np.argmax(nn(transformed_dataset.x_train).detach(), axis=1)\n",
    "pred_y_test = np.argmax(nn(transformed_dataset.x_test).detach(), axis=1)\n",
    "\n",
    "cm = confusion_matrix(dataset.y_test, pred_y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332e2b4",
   "metadata": {},
   "source": [
    "As one can see the accuracy is very close to 100% for the selected model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dbdd1e",
   "metadata": {},
   "source": [
    "## Calculating influences for small neural networks\n",
    "\n",
    "The following section elaborates the calculation of influences through a neural network. It is noteworthy that the full Hessian matrix is constructed and used for inverting the gradients. This can only be achieved for small networks. In the case of a big network additionally conjugate gradient has to be used to perform approximate inversion. The influences for both the train and test set are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "218d0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.influence.general import influences\n",
    "\n",
    "inversion_method = \"direct\" # cg for big networks\n",
    "\n",
    "#test_influences = influences(model, transformed_dataset.x_test, transformed_dataset.y_test, inversion_method=inversion_method)\n",
    "train_influences = influences(nn, F.cross_entropy, transformed_dataset, inversion_method=inversion_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f40ba",
   "metadata": {},
   "source": [
    "by the preceding code snippet. Subsequently, the mean absolute influence of one train sample onto all test samples is calculated by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9169c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_influences = lambda arr: np.mean(np.abs(arr), axis=0)\n",
    "mean_train_influences = mean_influences(train_influences)\n",
    "# mean_test_influences = mean_influences(test_influences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84630985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_dataset.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c29986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 142)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_influences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b81fc",
   "metadata": {},
   "source": [
    "a visual inspection yields that there are indeed different influential samples.\n",
    "\n",
    "## Keeping the most influential samples\n",
    "\n",
    "Using the pyDVL library, the next section selects the most influential samples and retrains the model using the shortened dataset. This is done over the number of samples to showcase how the weighted F1-score changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display_functions import display\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "num_estimates_per_samples = 5\n",
    "min_num_samples = 1\n",
    "metrics = {}\n",
    "x_range = range(min_num_samples, len(dataset), 5)\n",
    "\n",
    "for i, num_shortened_samples in enumerate(x_range):\n",
    "    display(f\"Iteration {i+1}/{len(x_range)}\")\n",
    "    summed_metric = 0\n",
    "\n",
    "    for j in range(num_estimates_per_samples):\n",
    "        idx = np.flip(np.argsort(mean_train_influences))[:num_shortened_samples]\n",
    "        shortened_dataset = copy(transformed_dataset)\n",
    "        shortened_dataset.x_train = shortened_dataset.x_train[idx]\n",
    "        shortened_dataset.y_train = shortened_dataset.y_train[idx]\n",
    "        shortened_model = TorchModule(\n",
    "            model=NeuralNetworkTorchModel(feature_dimension, num_classes, network_size),\n",
    "            objective=TorchObjective(F.cross_entropy, \"long\"),\n",
    "            num_epochs=300,\n",
    "            batch_size=32,\n",
    "            optimizer=TorchOptimizer.ADAM,\n",
    "            optimizer_kwargs={\n",
    "                \"lr\": 0.001,\n",
    "                \"weight_decay\": 0.001,\n",
    "                \"cosine_annealing\": True,\n",
    "            }\n",
    "        )\n",
    "        shortened_model.fit(\n",
    "            shortened_dataset.x_train,\n",
    "            shortened_dataset.y_train\n",
    "        )\n",
    "        pred_y_test = np.argmax(shortened_model.predict(transformed_dataset.x_test), axis=1)\n",
    "        summed_metric += f1_score(shortened_dataset.y_test, pred_y_test, average=\"weighted\")\n",
    "\n",
    "    metrics[num_shortened_samples] = summed_metric / num_estimates_per_samples\n",
    "\n",
    "metrics = pd.Series(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093bb27",
   "metadata": {},
   "source": [
    "Note, how the model is created completely new and is not derived from the previous model. This section showcases how to use the influence calculations The notebook finishes by plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420849a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "metrics.plot(xlabel=\"#samples\", ylabel=\"F1 score\", title=\"Weighted F1-Score over test set for number of most influential samples.\")\n",
    "hline_kwargs = {\n",
    "    \"linestyle\": \"--\",\n",
    "    \"color\": \"black\"\n",
    "}\n",
    "plt.axhline(0.0, **hline_kwargs)\n",
    "plt.axhline(1.0, **hline_kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66293554",
   "metadata": {},
   "source": [
    "the optimal number of samples on the x-axis along with the weighted F1-score on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdab62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_number_of_samples = metrics.index[metrics.argmax()]\n",
    "f\"The optimal number of samples is {optimal_number_of_samples}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e26cf",
   "metadata": {},
   "source": [
    "Over multiple runs with different the optimal number of samples canges, but it can be said to be safe to remove around 30% of the samples of the wine dataset to easily achieve the same data accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
