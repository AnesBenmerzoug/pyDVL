{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bd4dc3a",
   "metadata": {},
   "source": [
    "# Influence functions for data mislabeling\n",
    "\n",
    "\n",
    "Data mislabeling occurs whenever some examples from a usually big dataset are wrongly-labeled. This hardly violates the assumption that the data distribution of the data equals the hidden distribution of the real world. Hence, it is important to be able to restore such datasets automatically. In real-life scenarios, this happens fairly often and can have various reasons, e.g. problems with identifiability, human error, or noise in the data. Imagine a simple classification problem\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x_i &\\in \\mathbb{R}^d \\\\\n",
    "y_i &\\in \\{0, 1\\} \\\\\n",
    "\\forall i &\\in [ N ]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "containing $N$ samples. A classical example is whether a patient has a disease or not based on some feature representation $x$ of that person. Furthermore, this formalism applies to all datasets, which can be transformed to a vector of size $d$ by either linearization or other embedding techniques. For the described model the optimal decision boundary can be derived manually. This showed to be advantageous for educational purposes. Using a Bernoulli distribution on the classes $y$ and for the features $x$ a Gaussian distribution conditioned on the previous samples class label $y$. This can be formalized as a graphical model\n",
    "\n",
    "$$\n",
    "y_i \\sim \\text{Ber}\\left (0.5 \\right) \\\\\n",
    "x_i \\sim \\mathcal{N}\\left ((1 - y_i) \\mu_1 + y_i \\mu_2, \\sigma^2 I \\right),\n",
    "$$\n",
    "\n",
    "with fixed means and diagonal covariance. Implementing the sampling scheme in python is straightforward and can be achieved by first sampling $y$ and afterward $x$. More formally $x$ is a function of $y$ and not vice versa. The following code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from valuation.utils.numeric import sample_classification_dataset_using_gaussians\n",
    "\n",
    "num_samples = 10000\n",
    "num_features = 2\n",
    "sigma = 0.2\n",
    "mus = np.asarray([\n",
    "    [0.0, 0.0],\n",
    "    [1.0, 1.0]\n",
    "])\n",
    "\n",
    "num_classes = len(mus)\n",
    "x, y = sample_classification_dataset_using_gaussians(mus, sigma, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8a087",
   "metadata": {},
   "source": [
    "generates the aforementioned dataset. After the dataset was generated, a closer inspection of the data is performed. The following code snippet explicitly calculates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.utils.numeric import decision_boundary_fixed_variance_2d\n",
    "\n",
    "decision_boundary_fn = decision_boundary_fixed_variance_2d(mus[0], mus[1])\n",
    "decision_boundary = decision_boundary_fn(np.linspace(-1.5, 1.5, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945863fa",
   "metadata": {},
   "source": [
    " the decision boundary by mapping a continuous line of z values to a 2-dimensional vector in feature space. For more information view appendix A.\n",
    "\n",
    "## Plotting the dataset\n",
    "Next step consists in wrapping the previously generated data into a dataset with separate training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3cc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from valuation.utils import Dataset\n",
    "\n",
    "arg_flipper = lambda x1, x2, y1, y2: (x1, y1, x2, y2) # hacky\n",
    "dataset = Dataset(*arg_flipper(*train_test_split(x, y, train_size=0.70)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec223a74",
   "metadata": {},
   "source": [
    "Subsequently, the data is plotted with their respective class labels 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.utils.plotting import plot_datasets\n",
    "\n",
    "datasets = {\n",
    "    'train': (dataset.x_train, dataset.y_train),\n",
    "    'test': (dataset.x_test, dataset.y_test)\n",
    "}\n",
    "x_min = np.asarray([-2, -2])\n",
    "x_max = np.asarray([3, 3])\n",
    "plot_datasets(datasets, x_min=x_min, x_max=x_max, line=decision_boundary, s=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9b1d3",
   "metadata": {},
   "source": [
    "Note that both the train and test set are plotted side by side and the training samples overlap with the optimal decision boundary. These samples would get wrongly by any discriminator as this region has some identifiability issues.\n",
    "\n",
    "## Calculating influences using different reduction operators\n",
    "\n",
    "This section cares about how to calculate influences for this dataset under the assumption of using a logistic regression model for inferring the right labels. Using the pyDVL valuation library a model can be formalized and fitted by using just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.models import TorchOptimizer, TorchModule, TorchObjective\n",
    "from valuation.models import BinaryLogisticRegressionTorchModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = TorchModule(\n",
    "    model=BinaryLogisticRegressionTorchModel(num_features),\n",
    "    objective=TorchObjective(F.binary_cross_entropy),\n",
    "    num_epochs=100,\n",
    "    batch_size=128,\n",
    "    optimizer=TorchOptimizer.ADAM_W,\n",
    "    optimizer_kwargs={\n",
    "        \"lr\": 0.005,\n",
    "        \"weight_decay\": 0.005\n",
    "    },\n",
    ")\n",
    "model.fit(\n",
    "    dataset.x_train,\n",
    "    dataset.y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416eb518",
   "metadata": {},
   "source": [
    "It is important that the model converges to a point near the optimum, or otherwise the influence values will be of bad quality. Next the influences with respect to the previously fitted logistic regression model are calculated. A influence function\n",
    "\n",
    "$$I(x_1, y_1, x_2, y_2) \\colon \\mathbb{R}^d \\times \\mathbb{R}^d \\to \\mathbb{R}$$\n",
    "\n",
    "measures the influence of the data point $x_1$ onto $x_2$ conditioned on the training targets $y_1$ and $y_2$ trough some model parameters $\\theta$. As long as the loss function L is differentiable (or can be approximated by a surrogate objective) the influences\n",
    "\n",
    "$$\n",
    "I(x_1, x_2) = \\nabla_\\theta\\; L(x_1, y_1) ^\\mathsf{T} \\; H_\\theta^{-1} \\; \\nabla_\\theta \\; L(x_2, y_2)\n",
    "$$\n",
    "\n",
    "can be linearly approximated. Using the pyDVL library the influences can be estimated by the following snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.influence.general import influences\n",
    "from valuation.influence.types import InfluenceTypes\n",
    "train_influences = influences(\n",
    "    model,\n",
    "    dataset.x_train,\n",
    "    dataset.y_train,\n",
    "    dataset.x_test,\n",
    "    dataset.y_test,\n",
    "    influence_type=InfluenceTypes.Up\n",
    ")\n",
    "test_influences = influences(\n",
    "    model,\n",
    "    dataset.x_test,\n",
    "    dataset.y_test,\n",
    "    influence_type=InfluenceTypes.Up\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e98dc2",
   "metadata": {},
   "source": [
    "using autograd and explicit construction of the Hessian. Recall the train influences have shape [NxM] where N is the number of test samples and M is the number of training samples. The keene reader notices that, in order to obtain a valid ranking for the training data, each column of the aforementioned matrix has to be reduced to a single value, resulting overall in an vector of size [M]. There are various different choices in order to select See also appendix B. This notebook restricts to use the mean absolute influence to filter for the wrong data labels. After calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d186c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_influences = lambda arr: np.mean(np.abs(arr), axis=0)\n",
    "mean_train_influences = mean_influences(train_influences)\n",
    "mean_test_influences = mean_influences(test_influences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22020de",
   "metadata": {},
   "source": [
    "the data is again visualized along with their influences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd568ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_datasets = {\n",
    "    'train': (dataset.x_train, mean_train_influences),\n",
    "    'test': (dataset.x_test, mean_test_influences),\n",
    "}\n",
    "plot_datasets(influence_datasets, x_min=x_min, x_max=x_max, line=decision_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02ee04",
   "metadata": {},
   "source": [
    "## Flipping 5% of the training dataset and restore almost 80% of the flipped samples\n",
    "\n",
    "It is assumed that our reference test set is not flipped and was checked. Usually this is a viable solution as the test set is much smaller than the train set. First 5% of the training set get flipped at random positions. Second it is shown how to identify these examples. So a flipped dataset is created by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d798bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.utils.dataset import flip_dataset\n",
    "\n",
    "flipped_dataset, flipped_idx = flip_dataset(dataset, flip_percentage=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa17846",
   "metadata": {},
   "source": [
    "sampling random indices and inverting those. It is noteworthy to say that a new model has to fitted, because otherwise the old model contains information about the correct label of the specific data samples. Hence,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c93355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.models import TorchModule, TorchOptimizer, TorchObjective\n",
    "from valuation.models import BinaryLogisticRegressionTorchModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "flipped_model = TorchModule(\n",
    "    model=BinaryLogisticRegressionTorchModel(num_features),\n",
    "    objective=TorchObjective(F.binary_cross_entropy),\n",
    "    num_epochs=100,\n",
    "    batch_size=128,\n",
    "    optimizer=TorchOptimizer.ADAM_W,\n",
    "    optimizer_kwargs={\n",
    "        \"lr\": 0.005,\n",
    "        \"weight_decay\": 0.005\n",
    "    },\n",
    ")\n",
    "flipped_model.fit(\n",
    "    flipped_dataset.x_train,\n",
    "    flipped_dataset.y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dcd8fb",
   "metadata": {},
   "source": [
    "a new model is fitted with the pyDVL library. The newly obtained model is then used along with the flipped dataset to obtain the influences. Recall the aforementioned influence metrics and more specifically the mean absolute influence. For each training sample this metric is calculated and the 5% data points with the highest associated metric are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084de5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_train_test_influences = influences(\n",
    "    flipped_model,\n",
    "    flipped_dataset.x_train,\n",
    "    flipped_dataset.y_train,\n",
    "    flipped_dataset.x_test,\n",
    "    flipped_dataset.y_test,\n",
    "    influence_type=InfluenceTypes.Up\n",
    ")\n",
    "mean_flipped_train_test_influences = mean_influences(flipped_train_test_influences)\n",
    "estimated_idx = np.flip(np.argsort(mean_flipped_train_test_influences))[:len(flipped_idx)]\n",
    "found_elements = set(estimated_idx).intersection(set(flipped_idx))\n",
    "remaining_element = set(flipped_idx).difference(set(estimated_idx))\n",
    "f\"Around {100* len(found_elements) / len(flipped_idx):.2f}% could be identified. But there are {100* len(remaining_element) / len(flipped_idx):.2f}% remaining samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbebd9",
   "metadata": {},
   "source": [
    "Furthermore, the accuracy is evaluated, e.g. the number of same elements in the ground truth and the detected samples. Depending on the dataset a detection of up to 80% percent could be achieved. One might further inspect the selection method for the indices as it only selects the highest influence points as flipped samples. Furthermore, it is unclear how flipping all samples back and retraining the model affects the loss of the initial dataset.\n",
    "\n",
    "\n",
    "# Appendix\n",
    "\n",
    "## Appendix A: Calculating the decision boundary\n",
    "\n",
    "For obtaining the optimal discriminator one has to solve the equation\n",
    "\n",
    "$$p(x|y=0)=p(x|y=1)$$\n",
    "\n",
    "and determine the solution set $X$. A closed-form solution can be found, if the pdf of both classes can be written in closed form. In the general case, this decision boundary must not be linear. However, in the case of two Gaussians\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(x|y=0)&=\\mathcal{N}\\left (\\mu_1, \\sigma^2 I \\right) \\\\\n",
    "p(x|y=1)&=\\mathcal{N}\\left (\\mu_2, \\sigma^2 I \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "the boundary is linear and is straightforward to derive it. The complete case with different full covariances is left to the reader as an exercise. For a single fixed diagonal variance parameterized by $\\sigma$ the equation can be directly rewritten as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\| x - \\mu_1 \\|^2 &= \\| x - \\mu_2 \\|^2 \\\\\n",
    "\\| \\mu_1 \\|^2 -2 x^\\mathsf{T} \\mu_1 &= \\| \\mu_2 \\|^2 -2 x^\\mathsf{T} \\mu_2 \\\\\n",
    "\\implies 0 &= 2 (\\mu_2 - \\mu_1)^\\mathsf{T} x + \\| \\mu_1 \\|^2 - \\| \\mu_2 \\|^2 \\\\\n",
    "0 &= \\mu_1^\\mathsf{T}x - \\mu_2^\\mathsf{T}x - \\frac{1}{2} \\mu_1^\\mathsf{T} \\mu_1 + \\frac{1}{2} \\mu_2^\\mathsf{T} \\mu_2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "by using linear decision theory (see [Bishop C. 2006] for more details). However, this implicit description has to be transferred to an explicit one to effectively use it in python. Solving for the explicit form can be achieved by enforcing a functional form $f(z) = x = a z + b$ with $z \\in \\mathbb{R}$ onto $x$. After the term is inserted in the previous equation\n",
    "\n",
    "$$\n",
    "0 = (\\mu_2 - \\mu_1)^\\mathsf{T} (az + b) + \\frac{1}{2} \\| \\mu_1 \\|^2 - \\| \\mu_2 \\|^2\n",
    "$$\n",
    "\n",
    "by setting $a$ to be explicitly orthogonal to $\\mu_2 - \\mu_1$ and then solving for $b$ the solution\n",
    "\n",
    "$$\n",
    "f(z) = \\underbrace{\\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix} (\\mu_2 - \\mu_1)}_a z + \\underbrace{\\frac{\\mu_1 + \\mu_2}{2}}_b\n",
    "$$\n",
    "\n",
    "for the functional form $f(z) = a z + b$ can be obtained.\n",
    "\n",
    "## Appendix B: Different influence aggregation methods\n",
    "\n",
    "A few strictly positive sample metrics\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{MAI}(x) &= \\frac{1}{N} \\sum_{i=1}^N | I(x, x_i) | \\\\\n",
    "\\text{PMAI}(x) &= \\frac{1}{N} \\sum_{i=1}^N \\max(0, I(x, x_i))  \\\\\n",
    "\\text{NMAI}(x) &= \\frac{1}{N} \\sum_{i=1}^N \\max(0, -I(x, x_i))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "are given. Note the functional relation $\\text{MAI}(x) = \\text{PMAI}(x) + \\text{NMAI}(x)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
