{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence functions for Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the use of influences functions for convolutional neural networks. In the first part we will fine-tune Resnet18 on a (subset) of images taken from the [tiny-imagenet dataset](https://huggingface.co/datasets/Maysee/tiny-imagenet). This dataset was first created for the [Stanford Deep Learning for Computer Vision](http://cs231n.stanford.edu/) course, and it contains a subset of the images (200 classes vs 1000) that are found in the [famous ImageNet dataset](https://image-net.org/challenges/LSVRC/2012/index), downsampled to a lower-resolution (64x64 pixels vs 256x256). \n",
    "\n",
    "After training the last layers of the network, we will use pyDVL to find the most and least influential points on the evaluation images. This can be used e.g. to explain errors in the inference of new images or to direct efforts for collecting new data. In the last part the notebook we will also see that influence functions are an effective tool for finding anomalous or corrupted data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more about the (essential) theory that is at the foundation of influence functions for neural networks, you can find it in the appendix to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now proceed with the code! We will start by loading the imports and defining some utility methods to save and load models and influences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from pydvl.utils.dataset import load_preprocess_imagenet\n",
    "from pydvl.influence.model_wrappers import TorchModel\n",
    "from pydvl.influence.general import compute_influences\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "is_CI = os.environ.get(\"CI\")\n",
    "\n",
    "run_model_trainings = True\n",
    "calculate_influences = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from cloudpickle import pickle as pkl\n",
    "\n",
    "imgnet_model_data_path = Path().resolve().parent / \"data/imgnet_model\"\n",
    "\n",
    "\n",
    "def save_model(model, train_loss, val_loss, model_name):\n",
    "    torch.save(model.state_dict(), imgnet_model_data_path / f\"{model_name}_weights.pth\")\n",
    "    with open(\n",
    "        imgnet_model_data_path / f\"{model_name}_train_val_loss.pkl\", \"wb\"\n",
    "    ) as file:\n",
    "        pkl.dump([train_loss, val_loss], file)\n",
    "\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(\n",
    "        torch.load(imgnet_model_data_path / f\"{model_name}_weights.pth\")\n",
    "    )\n",
    "    with open(\n",
    "        imgnet_model_data_path / f\"{model_name}_train_val_loss.pkl\", \"rb\"\n",
    "    ) as file:\n",
    "        train_loss, val_loss = pkl.load(file)\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def save_results(results, file_name):\n",
    "    with open(imgnet_model_data_path / f\"{file_name}\", \"wb\") as file:\n",
    "        pkl.dump(results, file)\n",
    "\n",
    "\n",
    "def load_results(file_name):\n",
    "    with open(imgnet_model_data_path / f\"{file_name}\", \"rb\") as file:\n",
    "        results = pkl.load(file)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also here define some plotting methods, which will be used to visualize some of the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(\n",
    "    dataset,\n",
    "    labels,\n",
    "    n_images_per_class=3,\n",
    "    figsize=(8, 8),\n",
    "):\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    fig, axes = plt.subplots(nrows=n_images_per_class, ncols=len(labels))\n",
    "    fig.suptitle(\"Examples of training images\")\n",
    "    for class_idx, class_label in enumerate(labels):\n",
    "        for img_idx, (_, img_data) in enumerate(\n",
    "            dataset[dataset[\"labels\"] == class_label].iterrows()\n",
    "        ):\n",
    "            axes[img_idx, class_idx].imshow(img_data[\"images\"])\n",
    "            axes[img_idx, class_idx].axis(\"off\")\n",
    "            axes[img_idx, class_idx].set_title(f\"img label: {class_label}\")\n",
    "            if img_idx + 1 >= n_images_per_class:\n",
    "                break\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_top_bottom_if_images(\n",
    "    subset_influences,\n",
    "    subset_images,\n",
    "    num_to_plot,\n",
    "    figsize=(8, 8),\n",
    "):\n",
    "    top_if_idxs = np.argsort(subset_influences)[-num_to_plot:]\n",
    "    bottom_if_idxs = np.argsort(subset_influences)[:num_to_plot]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_to_plot, ncols=2)\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    fig.suptitle(\"Botton (left) and top (right) influences\")\n",
    "\n",
    "    for plt_idx, img_idx in enumerate(bottom_if_idxs):\n",
    "        axes[plt_idx, 0].set_title(f\"img influence: {subset_influences[img_idx]:0f}\")\n",
    "        axes[plt_idx, 0].imshow(subset_images[img_idx])\n",
    "        axes[plt_idx, 0].axis(\"off\")\n",
    "\n",
    "    for plt_idx, img_idx in enumerate(top_if_idxs):\n",
    "        axes[plt_idx, 1].set_title(f\"img influence: {subset_influences[img_idx]:0f}\")\n",
    "        axes[plt_idx, 1].imshow(subset_images[img_idx])\n",
    "        axes[plt_idx, 1].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is loaded through the load_preprocess_imagenet method. We will load the images related to the classes 90 and 100. This is an arbitrary choice and any other class would have worked. You can try selecting any other set of numbers, even more than just two (you could even select all 200 classes, though this will require longer training times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_keep = [90, 100]\n",
    "train_ds, val_ds, test_ds = load_preprocess_imagenet(\n",
    "    train_size=0.8,\n",
    "    test_size=0.1,\n",
    "    keep_labels=labels_to_keep,\n",
    "    is_CI=is_CI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data, let's take a look at a sample of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_images(train_ds, labels_to_keep, n_images_per_class=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first class is related to dining tables, the second to boats and to Venice! Let's now further pre-process the data and prepare for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_label_to_model_label = {ds_label: idx for idx, ds_label in enumerate(labels_to_keep)}\n",
    "model_label_to_ds_label = {idx: ds_label for idx, ds_label in enumerate(labels_to_keep)}\n",
    "\n",
    "\n",
    "def get_model_io(x, y):\n",
    "    x_nn = torch.stack(x.tolist())\n",
    "    y_nn = [ds_label_to_model_label[yi] for yi in y]\n",
    "    return x_nn, y_nn\n",
    "\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train_x, train_y = get_model_io(train_ds[\"normalized_images\"], train_ds[\"labels\"])\n",
    "val_x, val_y = get_model_io(val_ds[\"normalized_images\"], val_ds[\"labels\"])\n",
    "test_x, test_y = get_model_io(test_ds[\"normalized_images\"], test_ds[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will proceed with the initialization of the model and of some helper methods for training and evaluation. \n",
    "\n",
    "The model is defined by loading resnet18 and then switching the last few layers so that we can do binary classification on our selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(output_size):\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Finetune Final few layers to adjust for tiny imagenet input\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, output_size)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = initialize_model(output_size=len(labels_to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is done through some pytorch convenience wrappers (TorchModel) which are part of pyDVL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, training_data, lr=0.001):\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    get_model_io(training_data[\"normalized_images\"], training_data[\"labels\"])\n",
    "    train_x, train_y = get_model_io(\n",
    "        training_data[\"normalized_images\"], training_data[\"labels\"]\n",
    "    )\n",
    "\n",
    "    train_loss, val_loss = TorchModel(model=model).fit(\n",
    "        x_train=train_x,\n",
    "        y_train=train_y,\n",
    "        x_val=val_x,\n",
    "        y_val=val_y,\n",
    "        loss=ce_loss,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def plot_train_val_loss(train_loss, val_loss, figsize=(10, 8)):\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    plt.plot(train_loss, label=\"Train\")\n",
    "    plt.plot(val_loss, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_f1_score_on_test_set(model):\n",
    "    pred_y_test = np.argmax(model(test_x).detach(), axis=1)\n",
    "    return f1_score(test_y, pred_y_test, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and influence computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model for 50 epochs and save the results. Then we will plot the train and validation loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_model_trainings:\n",
    "    num_epochs = 50\n",
    "    train_loss, val_loss = train_model(\n",
    "        model_ft, num_epochs=num_epochs, training_data=train_ds\n",
    "    )\n",
    "    save_model(model_ft, train_loss, val_loss, model_name=\"model_ft\")\n",
    "else:\n",
    "    train_loss, val_loss = load_model(model_ft, model_name=\"model_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_loss(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix and f1 score are good, especially considering the low resolution of the images and their complexity (large diversity of objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_test = np.argmax(model_ft(test_x).detach(), axis=1)\n",
    "\n",
    "cm = confusion_matrix(test_y, pred_y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_to_keep)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_y, pred_y_test, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's calculate influences. The method compute_influences will take the trained model, a loss (which typically is the training loss, but not necessarily), some input dataset with labels (which typically are the training data, or a subset of it) and some test data (which in this case will be the validation set). \n",
    "\n",
    "Other important parameters are the hessian regularization term, which should be chosen as small as possible for the computation to converge. Details on why this is important can be found in the pyDVL documentation or in the [original paper](https://arxiv.org/pdf/1703.04730.pdf). \n",
    "\n",
    "Since the Resnet18 is quite big, the inversion methods that should be preferred is conjugate gradient (\"cg\"). The direct method would require a lot of memory. Finally, the influence type will be \"up\" (the other option, \"perturbation\", is beyond the scope of this notebook, but more info can be found in the influence_wine notebook or on the pyDVL documentation).\n",
    "\n",
    "The output of calculate_influences is a matrix of size (validation_set_length, training_set_length). Each row represents a validation data-point, and each column a training data-point. Each entry (i,j) represents the influence of training point j on the validation point i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_influences:\n",
    "    influences = compute_influences(\n",
    "        model=model_ft,\n",
    "        loss=ce_loss,\n",
    "        x=train_x,\n",
    "        y=train_y,\n",
    "        x_test=val_x,\n",
    "        y_test=val_y,\n",
    "        hessian_regularization=1e-3,\n",
    "        inversion_method=\"cg\",\n",
    "        influence_type=\"up\",\n",
    "    )\n",
    "    save_results(influences, file_name=\"influences.pkl\")\n",
    "else:\n",
    "    influences = load_results(file_name=\"influences.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the influence on validation images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an image in the validation set. Among the images in the training set, we will take those that have the same label and visualize those that have the highest and lowest influence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_idx = 118\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "plt.imshow(val_ds[\"images\"][val_image_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Predicted label:\",\n",
    "    model_label_to_ds_label[\n",
    "        np.argmax(model_ft(val_x[val_image_idx].unsqueeze(0)).detach(), axis=1).item()\n",
    "    ],\n",
    ")\n",
    "print(\"Real label:\", val_ds[\"labels\"][val_image_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "for label in labels_to_keep:\n",
    "    plt.hist(\n",
    "        influences[val_image_idx][train_ds[\"labels\"] == label], label=label, alpha=0.7\n",
    "    )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_same_label = train_ds[\"labels\"] == val_ds[\"labels\"][val_image_idx]\n",
    "if_same_label = influences[val_image_idx][images_with_same_label]\n",
    "imges_same_label = train_ds[\"images\"][images_with_same_label].values\n",
    "plot_top_bottom_if_images(if_same_label, subset_images=imges_same_label, num_to_plot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_influences = np.mean(influences, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "for label in labels_to_keep:\n",
    "    plt.hist(avg_influences[train_ds[\"labels\"] == label], label=label, alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 90\n",
    "img_with_selected_label = train_ds[\"labels\"] == label\n",
    "if_selected_label = avg_influences[img_with_selected_label]\n",
    "imges_same_label = train_ds[\"images\"][img_with_selected_label].values\n",
    "plot_top_bottom_if_images(if_selected_label, imges_same_label, num_to_plot=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the influence of corrupted training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrupted_dataset(dataset, fraction_to_corrupt, avg_influences):\n",
    "    indices_to_corrupt = []\n",
    "    corrupted_dataset = deepcopy(dataset)\n",
    "    corrupted_indices = {l: [] for l in labels_to_keep}\n",
    "\n",
    "    avg_influences_series = pd.DataFrame()\n",
    "    avg_influences_series[\"avg_influences\"] = avg_influences\n",
    "    avg_influences_series[\"labels\"] = dataset[\"labels\"]\n",
    "\n",
    "    for label in labels_to_keep:\n",
    "        class_data = avg_influences_series[avg_influences_series[\"labels\"] == label]\n",
    "        num_corrupt = int(fraction_to_corrupt * len(class_data))\n",
    "        indices_to_corrupt = class_data.nlargest(\n",
    "            num_corrupt, \"avg_influences\"\n",
    "        ).index.tolist()\n",
    "        wrong_labels = [l for l in labels_to_keep if l != label]\n",
    "        for img_idx in indices_to_corrupt:\n",
    "            sample_label = np.random.choice(wrong_labels)\n",
    "            corrupted_dataset.at[img_idx, \"labels\"] = sample_label\n",
    "            corrupted_indices[sample_label].append(img_idx)\n",
    "    return corrupted_dataset, corrupted_indices\n",
    "\n",
    "\n",
    "def plot_influence_distribution(\n",
    "    corrupted_dataset, corrupted_indices, avg_corrupted_influences, figsize=(16, 8)\n",
    "):\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "    fig.suptitle(\"Distribution of corrupted and clean influences.\")\n",
    "    avg_label_influence = pd.DataFrame(\n",
    "        columns=[\"label\", \"avg_non_corrupted_infl\", \"avg_corrupted_infl\"]\n",
    "    )\n",
    "    for idx, label in enumerate(labels_to_keep):\n",
    "        avg_influences_series = pd.Series(avg_corrupted_influences)\n",
    "        class_influences = avg_influences_series[corrupted_dataset[\"labels\"] == label]\n",
    "        corrupted_infl = class_influences[\n",
    "            class_influences.index.isin(corrupted_indices[label])\n",
    "        ]\n",
    "        non_corrupted_infl = class_influences[\n",
    "            ~class_influences.index.isin(corrupted_indices[label])\n",
    "        ]\n",
    "        avg_label_influence.loc[idx] = [\n",
    "            label,\n",
    "            np.mean(non_corrupted_infl),\n",
    "            np.mean(corrupted_infl),\n",
    "        ]\n",
    "        axes[idx].hist(\n",
    "            non_corrupted_infl, label=\"non corrupted data\", density=True, alpha=0.7\n",
    "        )\n",
    "        axes[idx].hist(corrupted_infl, label=\"corrupted data\", density=True, alpha=0.7)\n",
    "        axes[idx].set_xlabel(\"influence values\")\n",
    "        axes[idx].set_ylabel(\"Points distribution\")\n",
    "        axes[idx].set_title(f\"influences for {label=}\")\n",
    "        axes[idx].legend()\n",
    "    plt.show()\n",
    "    return avg_label_influence.astype({\"label\": \"int32\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_corrupted = initialize_model(output_size=len(labels_to_keep))\n",
    "corrupted_dataset, corrupted_indices = get_corrupted_dataset(\n",
    "    dataset=train_ds,\n",
    "    fraction_to_corrupt=0.1,\n",
    "    avg_influences=avg_influences,\n",
    ")\n",
    "\n",
    "if run_model_trainings:\n",
    "    num_epochs = 50\n",
    "    train_loss, val_loss = train_model(\n",
    "        model_corrupted,\n",
    "        num_epochs=num_epochs,\n",
    "        training_data=corrupted_dataset,\n",
    "    )\n",
    "    save_model(model_corrupted, train_loss, val_loss, model_name=\"model_corrupted\")\n",
    "else:\n",
    "    train_loss, val_loss = load_model(model_corrupted, model_name=\"model_corrupted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_loss(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = get_f1_score_on_test_set(model_corrupted)\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_influences:\n",
    "    corrupted_train_x, corrupted_train_y = get_model_io(\n",
    "        corrupted_dataset[\"normalized_images\"],\n",
    "        corrupted_dataset[\"labels\"],\n",
    "    )\n",
    "    influences = compute_influences(\n",
    "        model=model_corrupted,\n",
    "        loss=ce_loss,\n",
    "        x=corrupted_train_x,\n",
    "        y=corrupted_train_y,\n",
    "        x_test=val_x,\n",
    "        y_test=val_y,\n",
    "        hessian_regularization=1e-3,\n",
    "        inversion_method=\"cg\",\n",
    "        influence_type=\"up\",\n",
    "    )\n",
    "    save_results(influences, file_name=\"influences_corrupted.pkl\")\n",
    "else:\n",
    "    influences = load_results(file_name=\"influences_corrupted.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_corrupted_influences = np.mean(influences, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 100\n",
    "img_with_selected_label = corrupted_dataset[\"labels\"] == label\n",
    "if_selected_label = avg_corrupted_influences[img_with_selected_label]\n",
    "imges_same_label = corrupted_dataset[\"images\"][img_with_selected_label].values\n",
    "plot_top_bottom_if_images(if_selected_label, imges_same_label, num_to_plot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_label_influence = plot_influence_distribution(\n",
    "    corrupted_dataset, corrupted_indices, avg_corrupted_influences\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_label_influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Theory of Influence functions for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this appendix we will briefly go through the essential formulas that lay the foundations of influnce functions for neural networks. A more in-depth and expanded analysis can be found on the original paper: [\"Understanding Black-box Predictions via Influence Functions\"](https://arxiv.org/pdf/1703.04730.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by considering some input space $\\mathcal{X}$ to a model (e.g. images) and an output space $\\mathcal{Y}$ (e.g. labels). Let's take $z_i = (x_i, y_i)$ to be the training points, and $\\theta$ to be the (potentially highly) multi-dimensional parameters of the neural network (i.e. $\\theta$ is a big array with very many parameters). We will indicate with $L(z, \\theta)$ the loss of the model for point $z$ and parameters $\\theta$. When training the model, we want to minimize some sort of \"empirical risk\". The optimal parameters can then be (formally) found through minimization of the following formula:\n",
    "$$\n",
    "\\hat{\\theta} = \\arg \\min_\\theta \\frac{1}{n}\\sum_{i=1}^n L(z_i, \\theta)\n",
    "$$\n",
    "\n",
    "In order to understand the effect of training points on model prediction, we would like to study how much the model (i.e. $\\theta$) changes if a training point is added or removed. However, re-training the model for each data-points is prohibitively slow, especially for big neural networks. To circumvent this problem, influence functions up-weigh the importance of each point by an infinitesimal $\\epsilon$ and calculate the change in $\\theta$ (actually, its gradient) through backpropagation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dval_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3369ace3ad477f5e763d9fa7767e0177027059e92a8b1ded9e92b707c0b1513"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
