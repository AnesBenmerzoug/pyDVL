{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence functions in Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from cloudpickle import pickle as pkl\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydvl.influence.general import compute_influences\n",
    "from torch.optim import lr_scheduler, SGD\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from pydvl.utils.dataset import load_preprocess_imagenet\n",
    "from pydvl.influence.model_wrappers import TorchModel\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes_to_keep = 10\n",
    "train_ds, val_ds, test_ds = load_preprocess_imagenet(\n",
    "    train_size=0.8, test_size=0.1, keep_labels=list(range(n_classes_to_keep))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in train_ds[\"images\"][:3]:\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = resnet18(weights=True)\n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Finetune Final few layers to adjust for tiny imagenet input\n",
    "model_ft.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, n_classes_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft.to(device)\n",
    "\n",
    "train_model = False\n",
    "model_data_path = Path().resolve().parent / \"data/imgnet_model\"\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "def save_model(path, model, train_loss, val_loss):\n",
    "    torch.save(model.state_dict(), path / \"model_weights.pth\")\n",
    "    with open(path / \"train_val_loss.pkl\", \"wb\") as file:\n",
    "        pkl.dump([train_loss, val_loss], file)\n",
    "\n",
    "\n",
    "def load_model(path, model):\n",
    "    model.load_state_dict(torch.load(path / \"model_weights.pth\"))\n",
    "    with open(model_data_path / \"train_val_loss.pkl\", \"rb\") as file:\n",
    "        train_loss, val_loss = pkl.load(file)\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "if train_model:\n",
    "    num_epochs = 5\n",
    "    train_loss, val_loss = TorchModel(model=model_ft).fit(\n",
    "        x_train=torch.stack(train_ds[\"normalized_images\"]),\n",
    "        y_train=train_ds[\"labels\"],\n",
    "        x_val=torch.stack(val_ds[\"normalized_images\"]),\n",
    "        y_val=val_ds[\"labels\"],\n",
    "        loss=ce_loss,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    save_model(model_data_path, model_ft, train_loss, val_loss)\n",
    "else:\n",
    "    load_model(model_data_path, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "ax.plot(train_loss, label=\"Train\")\n",
    "ax.plot(val_loss, label=\"Val\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_test = np.argmax(\n",
    "    model_ft(torch.stack(test_ds[\"normalized_images\"])).detach(), axis=1\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(test_ds[\"labels\"], pred_y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_ds[\"labels\"], pred_y_test, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influences = compute_influences(\n",
    "    model_ft,\n",
    "    ce_loss,\n",
    "    x=torch.stack(train_ds[\"normalized_images\"][400:600]),\n",
    "    y=train_ds[\"labels\"][400:600],\n",
    "    x_test=torch.stack(val_ds[\"normalized_images\"][:300]),\n",
    "    y_test=val_ds[\"labels\"][:300],\n",
    "    hessian_regularization=0.01,\n",
    "    inversion_method=\"cg\",\n",
    "    influence_type=\"up\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_influences = np.mean(influences, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(avg_influences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(n_classes_to_keep):\n",
    "    plt.hist(\n",
    "        avg_influences[np.array(train_ds[\"labels\"][400:600]) == label], label=label\n",
    "    )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_influences[np.argsort(avg_influences)[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 20\n",
    "plt.imshow(val_ds[\"images\"][img_idx])\n",
    "print(val_ds[\"labels\"][img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(n_classes_to_keep):\n",
    "    if label == 5:\n",
    "        continue\n",
    "    plt.hist(\n",
    "        influences[20][np.array(train_ds[\"labels\"][200:400]) == label], label=label\n",
    "    )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_ds[\"labels\"][400:600])[np.argsort(influences[8])[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_idx in np.argsort(avg_influences)[:10]:\n",
    "    print(avg_influences[img_idx])\n",
    "    print(train_ds[\"labels\"][400:600][img_idx])\n",
    "    plt.imshow(train_ds[\"images\"][400:600][img_idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(train_ds[\"images\"][:200]):\n",
    "    if train_ds[\"labels\"][:200][idx] == 5:\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influences[8][(influences[8] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(train_ds[\"labels\"][:200])[~(influences[8] > 1)] == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_n = 40\n",
    "for i in range(20):\n",
    "    print(val_target[:100:5][i])\n",
    "    plt.imshow(result[i][image_n][0])\n",
    "    print(np.mean(result[i][image_n][0]))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(processed_tiny_imagenet[\"original_image\"][:500:10][image_n])\n",
    "print(processed_tiny_imagenet[\"labels\"][:500:10][image_n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dval_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3369ace3ad477f5e763d9fa7767e0177027059e92a8b1ded9e92b707c0b1513"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
