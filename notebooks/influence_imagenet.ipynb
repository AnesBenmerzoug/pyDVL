{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence functions in Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler, SGD\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from pydvl.utils.dataset import load_preprocess_imagenet\n",
    "from pydvl.influence.model_wrappers import TorchModel\n",
    "from pydvl.influence.general import compute_influences\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 8)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from cloudpickle import pickle as pkl\n",
    "\n",
    "imgnet_model_data_path = Path().resolve().parent / \"data/imgnet_model\"\n",
    "\n",
    "\n",
    "def save_model(model, train_loss, val_loss):\n",
    "    torch.save(model.state_dict(), imgnet_model_data_path / \"model_weights.pth\")\n",
    "    with open(imgnet_model_data_path / \"train_val_loss.pkl\", \"wb\") as file:\n",
    "        pkl.dump([train_loss, val_loss], file)\n",
    "\n",
    "\n",
    "def load_model(model):\n",
    "    model.load_state_dict(torch.load(imgnet_model_data_path / \"model_weights.pth\"))\n",
    "    with open(imgnet_model_data_path / \"train_val_loss.pkl\", \"rb\") as file:\n",
    "        train_loss, val_loss = pkl.load(file)\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def save_influences(influences):\n",
    "    with open(imgnet_model_data_path / \"influences.pkl\", \"wb\") as file:\n",
    "        pkl.dump(influences, file)\n",
    "\n",
    "\n",
    "def load_influences():\n",
    "    with open(imgnet_model_data_path / \"influences.pkl\", \"rb\") as file:\n",
    "        influences = pkl.load(file)\n",
    "    return influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_keep = list(range(50, 110, 10))\n",
    "train_ds, val_ds, test_ds = load_preprocess_imagenet(\n",
    "    train_size=0.8, test_size=0.1, keep_labels=labels_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images_per_class = 3\n",
    "fig, axes = plt.subplots(nrows=n_images_per_class, ncols=len(labels_to_keep))\n",
    "fig.suptitle(\"Examples of training images\")\n",
    "for class_idx, class_label in enumerate(labels_to_keep):\n",
    "    for img_idx, (_, img_data) in enumerate(\n",
    "        train_ds[train_ds[\"labels\"] == class_label].iterrows()\n",
    "    ):\n",
    "        axes[img_idx, class_idx].imshow(img_data[\"images\"])\n",
    "        axes[img_idx, class_idx].axis(\"off\")\n",
    "        axes[img_idx, class_idx].set_title(f\"img label: {class_label}\")\n",
    "        if img_idx + 1 >= n_images_per_class:\n",
    "            break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = resnet18(weights=True)\n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Finetune Final few layers to adjust for tiny imagenet input\n",
    "model_ft.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(labels_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "ds_label_to_model_label = {ds_label: idx for idx, ds_label in enumerate(labels_to_keep)}\n",
    "model_label_to_ds_label = {idx: ds_label for idx, ds_label in enumerate(labels_to_keep)}\n",
    "\n",
    "\n",
    "def get_model_io(x, y):\n",
    "    x_nn = torch.stack(x.tolist())\n",
    "    y_nn = [ds_label_to_model_label[yi] for yi in y]\n",
    "    return x_nn, y_nn\n",
    "\n",
    "\n",
    "train_x, train_y = get_model_io(train_ds[\"normalized_images\"], train_ds[\"labels\"])\n",
    "val_x, val_y = get_model_io(val_ds[\"normalized_images\"], val_ds[\"labels\"])\n",
    "test_x, test_y = get_model_io(test_ds[\"normalized_images\"], test_ds[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft.to(device)\n",
    "\n",
    "if train_model:\n",
    "    num_epochs = 15\n",
    "    train_loss, val_loss = TorchModel(model=model_ft).fit(\n",
    "        x_train=train_x,\n",
    "        y_train=train_y,\n",
    "        x_val=val_x,\n",
    "        y_val=val_y,\n",
    "        loss=ce_loss,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    save_model(model_ft, train_loss, val_loss)\n",
    "else:\n",
    "    train_loss, val_loss = load_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "ax.plot(train_loss, label=\"Train\")\n",
    "ax.plot(val_loss, label=\"Val\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_test = np.argmax(model_ft(test_x).detach(), axis=1)\n",
    "\n",
    "cm = confusion_matrix(test_y, pred_y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_to_keep)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_y, pred_y_test, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_influences = True\n",
    "\n",
    "if calculate_influences:\n",
    "    influences = compute_influences(\n",
    "        model_ft,\n",
    "        ce_loss,\n",
    "        x=train_x,\n",
    "        y=train_y,\n",
    "        x_test=val_x,\n",
    "        y_test=val_y,\n",
    "        hessian_regularization=0.1,\n",
    "        inversion_method=\"cg\",\n",
    "        influence_type=\"up\",\n",
    "    )\n",
    "    save_influences(influences)\n",
    "else:\n",
    "    influences = load_influences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_idx = 110\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "plt.imshow(val_ds[\"images\"][val_image_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Predicted label:\",\n",
    "    model_label_to_ds_label[\n",
    "        np.argmax(model_ft(val_x[val_image_idx].unsqueeze(0)).detach(), axis=1).item()\n",
    "    ],\n",
    ")\n",
    "print(\"Real label:\", val_ds[\"labels\"][val_image_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_bottom_if_images(\n",
    "    subset_influences, subset_images, num_to_plot, figsize=(8, 8)\n",
    "):\n",
    "    top_if_idxs = np.argsort(subset_influences)[-num_to_plot:]\n",
    "    bottom_if_idxs = np.argsort(subset_influences)[:num_to_plot]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_to_plot, ncols=2)\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    fig.suptitle(\"Botton (left) and top (right) influences\")\n",
    "\n",
    "    for plt_idx, img_idx in enumerate(bottom_if_idxs):\n",
    "        axes[plt_idx, 0].set_title(f\"img influence: {subset_influences[img_idx]:0f}\")\n",
    "        axes[plt_idx, 0].imshow(subset_images[img_idx])\n",
    "        axes[plt_idx, 0].axis(\"off\")\n",
    "\n",
    "    for plt_idx, img_idx in enumerate(top_if_idxs):\n",
    "        axes[plt_idx, 1].set_title(f\"img influence: {subset_influences[img_idx]:0f}\")\n",
    "        axes[plt_idx, 1].imshow(subset_images[img_idx])\n",
    "        axes[plt_idx, 1].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "for label in labels_to_keep:\n",
    "    plt.hist(influences[val_image_idx][train_ds[\"labels\"] == label], label=label)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_same_label = train_ds[\"labels\"] == val_ds[\"labels\"][val_image_idx]\n",
    "if_same_label = influences[val_image_idx][images_with_same_label]\n",
    "imges_same_label = train_ds[\"images\"][images_with_same_label].values\n",
    "plot_top_bottom_if_images(if_same_label, subset_images=imges_same_label, num_to_plot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_influences = np.mean(influences, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "for label in labels_to_keep:\n",
    "    plt.hist(avg_influences[train_ds[\"labels\"] == label], label=label)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_bottom_if_images(avg_influences, train_ds[\"images\"], num_to_plot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_exclude = []\n",
    "fraction_to_exclude = 0.7\n",
    "\n",
    "train_ds[\"avg_influences\"] = avg_influences\n",
    "\n",
    "for label in labels_to_keep:\n",
    "    class_data = train_ds[train_ds[\"labels\"] == label]\n",
    "    num_exclude = int(fraction_to_exclude * len(class_data))\n",
    "    indices_to_exclude.extend(\n",
    "        class_data.nsmallest(num_exclude, \"avg_influences\").index.tolist()\n",
    "    )\n",
    "\n",
    "reduced_train_ds = train_ds.loc[~train_ds.index.isin(indices_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "optimizer = SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "red_train_x, red_train_y = get_model_io(\n",
    "    reduced_train_ds[\"normalized_images\"], reduced_train_ds[\"labels\"]\n",
    ")\n",
    "\n",
    "train_loss, val_loss = TorchModel(model=model_ft).fit(\n",
    "    x_train=red_train_x,\n",
    "    y_train=red_train_y,\n",
    "    x_val=val_x,\n",
    "    y_val=val_y,\n",
    "    loss=ce_loss,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "ax.plot(train_loss, label=\"Train\")\n",
    "ax.plot(val_loss, label=\"Val\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_test = np.argmax(model_ft(test_x).detach(), axis=1)\n",
    "\n",
    "f1_score(test_y, pred_y_test, average=\"weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dval_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3369ace3ad477f5e763d9fa7767e0177027059e92a8b1ded9e92b707c0b1513"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
